#### 如何定义一个优化器的执行批次

```scala
// 1. 操作符的优化结果集
val operatorOptimizationRuleSet =
      Seq(
        // 通过union下推投影
        PushProjectionThroughUnion,
        // 根据关系代数对join重排序,将所有条件放置到join中,这样底层节点的数据量会变少
        ReorderJoin,
        // 外连接消除  -- 使用谓词限制带有空值的行
        EliminateOuterJoin,
        // 谓词下推 可以用于级联join
        PushDownPredicates,
        // 不通过join下推谓词,使用if进行过滤函数置入
        PushDownLeftSemiAntiJoin,
        // 对于left semi join/ left anti join 的特殊谓词下推
        PushLeftSemiLeftAntiThroughJoin,
        // 下推位于union all 下面的limit
        LimitPushDown,
        // 列消除, 当过滤逻辑 和 根据投影的谓词下推出现冲突的时候, 这个投影就会被移除
        ColumnPruning,
        // 由限制条件推测过滤器
        InferFiltersFromConstraints,
        // 合并分区
        CollapseRepartition,
	   // 投影合并
        CollapseProject,
        // 合并窗口
        CollapseWindow,
        // 合并两个相邻的过滤条件,将非冗余条件合并成一个谓词
        CombineFilters,
        // limit合并 合并两个相邻的limit
        CombineLimits,
        // 合并两个相邻的union操作
        CombineUnions,
        // 窗口转置
        TransposeWindow,
        // 空值传递
        NullPropagation,
        // 常数传播 当一个属性是常数的时候,其他使用这个属性的地方会被替换为常数
        /**
             {{{
                 SELECT * FROM table WHERE i = 5 AND j = i + 3
                 ==>  SELECT * FROM table WHERE i = 5 AND j = 8
             }}}
        */
        ConstantPropagation,
        // 可折叠性传播 
        FoldablePropagation,
        // in表达式谓词的优化
        /**
        	1. 当in列表为空的时候且值为非可空, 将谓词值设置为false
        	2. 移除字面上的重复的
        	3. 替换表达式In (value, seq[Literal]) -> InSet (value, HashSet[Literal])
        */
        OptimizeIn,
        // 常数折叠 将值为常量的字面量替换为常量
        ConstantFolding,
        // 重排必要操作符,并将常数折叠成一个值
        ReorderAssociativeOperator,
        // like 表达式优化, 在不使用全正则表达式的情况下计算匹配条件
        LikeSimplification,
        // bool值简化
        /**
        	1. 短路表达式简化(不用计算所有条件)
        	2. 提出并移除公共因子
        	3. 合并表达式
        	4. 移除not操作符
        */
        BooleanSimplification,
          
        /**
        	1. 简化条件表达式if/case
        */
        SimplifyConditionals,
          
        // 移除无关表达式
        RemoveDispensableExpressions,
          
        // 简化比较操作符
        SimplifyBinaryComparison,
        
        // 谓词表达式中使用false替换null
        ReplaceNullWithFalseInPredicate,
          
        // 过滤器修剪
        /**
          过滤条件的修剪,通过下述的操作进行估量
          1. 如果过滤器估测的结果为true,则将过滤条件淘汰
          2. 在过滤器评测值为false的时候,替换为一个伪空关系
          3. 消除子节点输出中总是为true的条件
        */
        PruneFilters,
        
        // 简化 cast
        SimplifyCasts,
        
        // 简化内部无用的case表达式
        SimplifyCaseConversionExpressions,
        
        // 使用left join重写标量子查询
        RewriteCorrelatedScalarSubquery,
        
        // 消除序列化
        EliminateSerialization,
        
        // 移除多余的别名信息
        RemoveRedundantAliases,
        
        // 移除空操作符
        RemoveNoopOperators,
       	
        // 简化多余的创建数据结构表达式
        SimplifyExtractValueOps,
        
        // 连接内部的 concat表达式
        CombineConcats) ++
        extendedOperatorOptimizationRules

//2. 获取操作符优化批次信息
val operatorOptimizationBatch: Seq[Batch] = {
    val rulesWithoutInferFiltersFromConstraints =
    operatorOptimizationRuleSet.filterNot(_ == InferFiltersFromConstraints)
    Batch("Operator Optimization before Inferring Filters", fixedPoint,
          rulesWithoutInferFiltersFromConstraints: _*) ::
    Batch("Infer Filters", Once,
          InferFiltersFromConstraints) ::
    Batch("Operator Optimization after Inferring Filters", fixedPoint,
          rulesWithoutInferFiltersFromConstraints: _*) :: Nil
}

// 3. 获取优化批次信息
/*
    批次信息
    1. 去重信息
    2. 最终分析信息
    3. Union信息
    4. 优化零极限
    5. 早期本地相关处理(减少rule的遍历处理)
    6. 挂起相关的表达式
    7. 子查询优化
    8. 操作符替代优化
    9. 聚合优化
    10. 早期过滤条件和主属性的过滤
    11. join重排序
    12. 移除排序
    13. 十进制数的优化
    14. 对象表达式优化
    15. 本地相关性处理
    16. 检查笛卡尔积
    17. 重新子查询
    18. 浮点数正常化处理
     */
    val batches = (Batch("Eliminate Distinct", Once, EliminateDistinct) ::
    /*
    在最终分析(Finish Analysis)中的一些规则不是优化准则，且有些分析器中，因此需要修正。
    但是，因为页需要使用分析器去对查询进行规范化处理。因此在分析器中不应该消除子查询，或者计算当前时间
     */
    Batch("Finish Analysis", Once,
      EliminateResolvedHint,
      EliminateSubqueryAliases,
      EliminateView,
      ReplaceExpressions,
      ComputeCurrentTime,
      GetCurrentDatabase(catalogManager),
      RewriteDistinctAggregates,
      ReplaceDeduplicateWithAggregate) :
    /*
    优化器起始于此
    1. 在启动优化准则之前,进行Union合并@CombineUnions 的首次调用,因为其可以降低迭代器的数量且其他准则可以添加或者移除两个union
    操作间的额外操作.
    2. 调用批次的合并操作(其他准则可能有两个独立相连的union操作)
     */
    Batch("Union", Once,
      CombineUnions) ::
    Batch("OptimizeLimitZero", Once,
      OptimizeLimitZero) ::
    /*
    下面的操作会简化逻辑计划,且降低优化器的执行开销.
    例如,操作Filter(LocalRelation)会遍历所有优化器准则，这些准则当其为过滤器(例如InferFiltersFromConstraints)的时候
    会被触发.如果早期运行这个批次,查询会是本地相关的@LocalRelation,且不会触发那么多的准则
     */
    Batch("LocalRelation early", fixedPoint,
      ConvertToLocalRelation,
      PropagateEmptyRelation) ::
    Batch("Pullup Correlated Expressions", Once,
      PullupCorrelatedPredicates) ::
    /*
    子查询批次迭代的使用优化器规则,因此对其保证幂等性是毫无意义的,且会将批次从Once修改为FixedPoint(1)
     */
    Batch("Subquery", FixedPoint(1),
      OptimizeSubqueries) ::
    Batch("Replace Operators", fixedPoint,
      RewriteExceptAll,
      RewriteIntersectAll,
      ReplaceIntersectWithSemiJoin,
      ReplaceExceptWithFilter,
      ReplaceExceptWithAntiJoin,
      ReplaceDistinctWithAggregate) ::
    Batch("Aggregate", fixedPoint,
      RemoveLiteralFromGroupExpressions,
      RemoveRepetitionFromGroupExpressions) :: Nil ++
    operatorOptimizationBatch) :+
    /*
    这个批次会将过滤条件和主属性(projection)置入扫描节点中.在批次之前,逻辑计划会包含没有汇报状态的节点.
    使用状态的阶段必须在批次之后进行处理
     */
    Batch("Early Filter and Projection Push-Down", Once, earlyScanPushDownRules: _*) :+
    /*
    join重排序:
    AQP的jion代价会在多个线程运行中改变，所以不需要保证在批次中的幂等性。因此使用FixedPoint(1)而不是Once语义
     */
    Batch("Join Reorder", FixedPoint(1),
      CostBasedJoinReorder) :+
    Batch("Eliminate Sorts", Once,
      EliminateSorts) :+
    Batch("Decimal Optimizations", fixedPoint,
      DecimalAggregates) :+
    Batch("Object Expressions Optimization", fixedPoint,
      EliminateMapObjects,
      CombineTypedFilters,
      ObjectSerializerPruning,
      ReassignLambdaVariableID) :+
    Batch("LocalRelation", fixedPoint,
      ConvertToLocalRelation,
      PropagateEmptyRelation) :+
    // 下述操作需要在批次join重排序以及本地相关性处理之后进行
    Batch("Check Cartesian Products", Once,
      CheckCartesianProducts) :+
    Batch("RewriteSubquery", Once,
      RewritePredicateSubquery,
      ColumnPruning,
      CollapseProject,
      RemoveNoopOperators) :+
    // 浮点数的正常化处理,必须在重新子查询@RewriteSubquery 之后处理,这个会创建join
    Batch("NormalizeFloatingNumbers", Once, NormalizeFloatingNumbers)
    // 移除没有rule的批次,这个会当子类没有添加额外的规则的时候发生
    batches.filter(_.rules.nonEmpty)
  }
```



2. 设置黑白名单信息,启用/禁用某些优化规则

```scala
// 白名单
def nonExcludableRules: Seq[String] =
    EliminateDistinct.ruleName ::
      EliminateResolvedHint.ruleName ::
      EliminateSubqueryAliases.ruleName ::
      EliminateView.ruleName ::
      ReplaceExpressions.ruleName ::
      ComputeCurrentTime.ruleName ::
      GetCurrentDatabase(catalogManager).ruleName ::
      RewriteDistinctAggregates.ruleName ::
      ReplaceDeduplicateWithAggregate.ruleName ::
      ReplaceIntersectWithSemiJoin.ruleName ::
      ReplaceExceptWithFilter.ruleName ::
      ReplaceExceptWithAntiJoin.ruleName ::
      RewriteExceptAll.ruleName ::
      RewriteIntersectAll.ruleName ::
      ReplaceDistinctWithAggregate.ruleName ::
      PullupCorrelatedPredicates.ruleName ::
      RewriteCorrelatedScalarSubquery.ruleName ::
      RewritePredicateSubquery.ruleName ::
      NormalizeFloatingNumbers.ruleName :: Nil

// 黑名单
override protected val blacklistedOnceBatches: Set[String] =
```

#### 常见的优化方法

##### Join的优化

1.  Join重排序

   **原理: **利用关系代数的交换律, 对join顺序进行排序, 将所有查询条件放到`join`中, 这样底层的表会有至少一个谓词.

   如果每个Join都有一个谓词条件, 那么不用调换顺序. 

   **处理细节: **

   ```scala
   @tailrec
   final def createOrderedJoin(
       input: Seq[(LogicalPlan, InnerLike)], // (参加join的逻辑计划/join 类型)
       conditions: Seq[Expression] // join的谓词表达式表
   ): LogicalPlan = {
       assert(input.size >= 2)
       if (input.size == 2) {
           // 处理可join场合
           
           // 筛选查询条件
           val (joinConditions, others) = conditions.partition(canEvaluateWithinJoin)
           // 尾递归获取参与join的左/右表
           val ((left, leftJoinType), (right, rightJoinType)) = (input(0), input(1))
           val innerJoinType = (leftJoinType, rightJoinType) match {
               case (Inner, Inner) => Inner
               case (_, _) => Cross
           }
           
           // 生成基本join信息,其中join的谓词参数为`canEvaluateWithinJoin`为true的部分
           // 其他部分左右过滤条件的一部分放在后面,不参与join
           val join = Join(left, right, innerJoinType,
                           joinConditions.reduceLeftOption(And), JoinHint.NONE)
           if (others.nonEmpty) {
               Filter(others.reduceLeft(And), join)
           } else {
               join
           }
       } else {
           val (left, _) :: rest = input.toList
           // find out the first join that have at least one join condition
           val conditionalJoin = rest.find { planJoinPair =>
               val plan = planJoinPair._1
               val refs = left.outputSet ++ plan.outputSet
               conditions
               .filterNot(l => l.references.nonEmpty && canEvaluate(l, left))
               .filterNot(r => r.references.nonEmpty && canEvaluate(r, plan))
               .exists(_.references.subsetOf(refs))
           }
           // pick the next one if no condition left
           val (right, innerJoinType) = conditionalJoin.getOrElse(rest.head)
   
           val joinedRefs = left.outputSet ++ right.outputSet
           val (joinConditions, others) = conditions.partition(
               e => e.references.subsetOf(joinedRefs) && canEvaluateWithinJoin(e))
           val joined = Join(left, right, innerJoinType,
                             joinConditions.reduceLeftOption(And), JoinHint.NONE)
   
           // should not have reference to same logical plan
           createOrderedJoin(Seq((joined, Inner)) ++ rest.filterNot(_._1 eq right), others)
       }
   }
   ```

2. 消除外部连接

   当谓词可以限制输出结果的时候, 提供空值的行就会被消除. 这样可以等效的替代外连接.

   + 先确定表达式是否返回空值或者false

     ```scala
     private def canFilterOutNull(e: Expression): Boolean = {
         if (!e.deterministic || SubqueryExpression.hasCorrelatedSubquery(e)) return false
         //BoundReference 用于输入元组的快速检索,使用下标检索
         val attributes = e.references.toSeq
         val emptyRow = new GenericInternalRow(attributes.length)
         val boundE = BindReferences.bindReference(e, attributes)
         if (boundE.find(_.isInstanceOf[Unevaluable]).isDefined) return false
         // 对可能的空行进行计算
         val v = boundE.eval(emptyRow)
         v == null || v == false
     }
     
     // 属性绑定逻辑
     def bindReference[A <: Expression](
         expression: A,
         input: AttributeSeq,
         allowFailures: Boolean = false): A = {
         expression.transform { case a: AttributeReference =>
             attachTree(a, "Binding attribute") {
                 val ordinal = input.indexOf(a.exprId)
                 if (ordinal == -1) {
                     if (allowFailures) {
                         a
                     } else {
                         sys.error(s"Couldn't find $a in ${input.attrs.mkString("[", ",", "]")}")
                     }
                 } else {
                     BoundReference(ordinal, a.dataType, input(ordinal).nullable)
                 }
             }
         }.asInstanceOf[A] // Kind of a hack, but safe.  TODO: Tighten return type when possible.
     }
     ```

   + 生成新的Join类型

     ```scala
     private def buildNewJoinType(filter: Filter, join: Join): JoinType = {
         // 生成谓词和左右连接条件
         val conditions = splitConjunctivePredicates(filter.condition) ++ filter.constraints
         val leftConditions = conditions.filter(_.references.subsetOf(join.left.outputSet))
         val rightConditions = conditions.filter(_.references.subsetOf(join.right.outputSet))
     	
         // 确定左/右连接是否有空值
         lazy val leftHasNonNullPredicate = leftConditions.exists(canFilterOutNull)
         lazy val rightHasNonNullPredicate = rightConditions.exists(canFilterOutNull)
     
         // 进行空值优化
         join.joinType match {
             case RightOuter if leftHasNonNullPredicate => Inner
             case LeftOuter if rightHasNonNullPredicate => Inner
             case FullOuter if leftHasNonNullPredicate && rightHasNonNullPredicate => Inner
             case FullOuter if leftHasNonNullPredicate => LeftOuter
             case FullOuter if rightHasNonNullPredicate => RightOuter
             case o => o
         }
     }
     ```

##### 子查询优化

1. 重写子查询中的谓词表达式

   这个准则重写了谓词子查询到`left/anti join`中,支持以下类型谓词:

   1. `exist/not exist`会在`semi/anti join`中重写, 过滤器中未处理的函数会使用`join`拉取
   2. `in/not in`会使用`semi/anti join`中重写. 使用`join`拉取过滤器中谓词逻辑.

   **实现细节: **

   + 自连接时,重复子查询

     使用自连接的时候, join的两端会持有冲突的属性. 产生的join表达式不可解.  所以在这里使用重命名的方式对其重新投影. 解决命名冲突.

     ```scala
     private def dedupSubqueryOnSelfJoin(
         outerPlan: LogicalPlan,
         subplan: LogicalPlan,
         valuesOpt: Option[Seq[Expression]],
         condition: Option[Expression] = None): LogicalPlan = {
         // 找到父子查询间的重复属性
         val outerReferences = valuesOpt.map(values =>
           AttributeSet.fromAttributeSets(values.map(_.references))).getOrElse(AttributeSet.empty)
         val outerRefs = outerPlan.outputSet ++ outerReferences
         val duplicates = outerRefs.intersect(subplan.outputSet)
         if (duplicates.nonEmpty) {
           condition.foreach { e =>
               val conflictingAttrs = e.references.intersect(duplicates)
               if (conflictingAttrs.nonEmpty) {
                 throw new AnalysisException("Found conflicting attributes " +
                   s"${conflictingAttrs.mkString(",")} in the condition joining outer plan:\n  " +
                   s"$outerPlan\nand subplan:\n  $subplan")
               }
           }
           // 重写冲突属性命名方式
           val rewrites = AttributeMap(duplicates.map { dup =>
             dup -> Alias(dup, dup.toString)()
           }.toSeq)
           // 确定子查询的别名表达式
           val aliasedExpressions = subplan.output.map { ref =>
             rewrites.getOrElse(ref, ref)
           }
           // 对子查询中冲突属性进行重新投影
           Project(aliasedExpressions, subplan)
         } else {
           subplan
         }
     }
     
     // 重新构建join表达式
     rivate def buildJoin(
           outerPlan: LogicalPlan,
           subplan: LogicalPlan,
           joinType: JoinType,
           condition: Option[Expression]): Join = {
         val dedupSubplan = dedupSubqueryOnSelfJoin(outerPlan, subplan, None, condition)
         Join(outerPlan, dedupSubplan, joinType, condition, JoinHint.NONE)
       }
     ```

   + 将子查询改写成连接查询

     ```scala
     private def rewriteExistentialExpr(
         exprs: Seq[Expression],
         plan: LogicalPlan): (Option[Expression], LogicalPlan) = {
         var newPlan = plan
         val newExprs = exprs.map { e =>
             e transformUp {
                 case Exists(sub, conditions, _) =>
                 val exists = AttributeReference("exists", BooleanType, nullable = false)()
                 newPlan =
                 buildJoin(newPlan, sub, ExistenceJoin(exists), conditions.reduceLeftOption(And))
                 exists
                 
                 case InSubquery(values, ListQuery(sub, conditions, _, _)) =>
                 val exists = AttributeReference("exists", BooleanType, nullable = false)()
                 // Deduplicate conflicting attributes if any.
                 val newSub = dedupSubqueryOnSelfJoin(newPlan, sub, Some(values))
                 val inConditions = values.zip(newSub.output).map(EqualTo.tupled)
                 val newConditions = (inConditions ++ conditions).reduceLeftOption(And)
                 newPlan = Join(
                     newPlan, newSub, ExistenceJoin(exists), newConditions, JoinHint.NONE)
                 exists
             }
         }
         (newExprs.reduceOption(And), newPlan)
     }
     ```

2. 重写相关标量子查询

   将标量子查询重写为左连接的形式

   + 标量子查询

     仅仅返回一行或者一列的子查询叫做标量子查询. 会被转化为物理标量子查询.

     ```scala
     case class ScalarSubquery(
         plan: LogicalPlan,
         children: Seq[Expression] = Seq.empty,
         exprId: ExprId = NamedExpression.newExprId)
     extends SubqueryExpression(plan, children, exprId) with Unevaluable 
     ```

   + 将标量查询分割成多个部分

     ```scala
     private def splitSubquery(plan: LogicalPlan) : (Seq[LogicalPlan], Option[Filter], Aggregate) = {
         val topPart = ArrayBuffer.empty[LogicalPlan]
         var bottomPart: LogicalPlan = plan
         while (true) {
             bottomPart match {
                 case havingPart @ Filter(_, aggPart: Aggregate) =>
                 return (topPart, Option(havingPart), aggPart)
     
                 case aggPart: Aggregate =>
                 // No HAVING clause
                 return (topPart, None, aggPart)
     
                 case p @ Project(_, child) =>
                 topPart += p
                 bottomPart = child
     
                 case s @ SubqueryAlias(_, child) =>
                 topPart += s
                 bottomPart = child
     
                 case Filter(_, op) =>
                 sys.error(s"Correlated subquery has unexpected operator $op below filter")
     
                 case op @ _ => sys.error(s"Unexpected operator $op in correlated subquery")
             }
         }
     
         sys.error("This line should be unreachable")
     }
     ```

   + 对于空输入的标量查询评估

     ```scala
     private def evalSubqueryOnZeroTups(plan: LogicalPlan) : Option[Expression] = {
         // Inputs to this method will start with a chain of zero or more SubqueryAlias
         // and Project operators, followed by an optional Filter, followed by an
         // Aggregate. Traverse the operators recursively.
         def evalPlan(lp : LogicalPlan) : Map[ExprId, Expression] = lp match {
             case SubqueryAlias(_, child) => evalPlan(child)
             case Filter(condition, child) =>
                 val bindings = evalPlan(child)
                 if (bindings.isEmpty) {
                     bindings
                 } else {
                     val bindCondition = bindingExpr(condition, bindings)
     
                     if (!bindCondition.foldable) {
                         // We can't evaluate the condition. Evaluate it in query runtime.
                         bindings.map { case (id, expr) =>
                             val newExpr = 
                             	If(bindCondition, expr, Literal.create(null, expr.dataType))
                             (id, newExpr)
                         }
                     } else {
                         // The bound condition can be evaluated.
                         bindCondition.eval() match {
                             // For filter condition, null is the same as false.
                             case null | false => Map.empty
                             case true => bindings
                         }
                     }
                 }
     
             case Project(projectList, child) =>
             val bindings = evalPlan(child)
             if (bindings.isEmpty) {
                 bindings
             } else {
                 projectList.map(ne => (ne.exprId, bindingExpr(ne, bindings))).toMap
             }
     
             case Aggregate(_, aggExprs, _) =>
             // Some of the expressions under the Aggregate node are the join columns
             // for joining with the outer query block. Fill those expressions in with
             // nulls and statically evaluate the remainder.
             aggExprs.map {
                 case ref: AttributeReference => (ref.exprId, Literal.create(null, ref.dataType))
                 case alias @ Alias(_: AttributeReference, _) =>
                 (alias.exprId, Literal.create(null, alias.dataType))
                 case ne => (ne.exprId, evalAggOnZeroTups(ne))
             }.toMap
     
             case _ =>
             sys.error(s"Unexpected operator in scalar subquery: $lp")
         }
     
         val resultMap = evalPlan(plan)
     
         // By convention, the scalar subquery result is the leftmost field.
         resultMap.get(plan.output.head.exprId) match {
             case Some(Literal(null, _)) | None => None
             case o => o
         }
     }
     ```

     

   + 标量查询转化为左连接

     ```scala
     private def constructLeftJoins(
         child: LogicalPlan,
         subqueries: ArrayBuffer[ScalarSubquery]): LogicalPlan = {
         subqueries.foldLeft(child) {
             case (currentChild, ScalarSubquery(query, conditions, _)) =>
             val origOutput = query.output.head
     
             val resultWithZeroTups = evalSubqueryOnZeroTups(query)
             if (resultWithZeroTups.isEmpty) {
                 // 单个标量查询,不会出现count问题,直接作投影
                 // CASE 1: Subquery guaranteed not to have the COUNT bug
                 Project(
                     currentChild.output :+ origOutput,
                     Join(currentChild, query, LeftOuter, conditions.reduceOption(And), JoinHint.NONE))
             } else {
                 // 分割查询,避免count问题
                 // Subquery might have the COUNT bug. Add appropriate corrections.
                 val (topPart, havingNode, aggNode) = splitSubquery(query)
     
                 // The next two cases add a leading column to the outer join input to make it
                 // possible to distinguish between the case when no tuples join and the case
                 // when the tuple that joins contains null values.
                 // The leading column always has the value TRUE.
                 val alwaysTrueExprId = NamedExpression.newExprId
                 val alwaysTrueExpr = Alias(Literal.TrueLiteral,
                                            ALWAYS_TRUE_COLNAME)(exprId = alwaysTrueExprId)
                 val alwaysTrueRef = AttributeReference(ALWAYS_TRUE_COLNAME,
                                                        BooleanType)(exprId = alwaysTrueExprId)
     
                 val aggValRef = query.output.head
     
                 if (havingNode.isEmpty) {
                     // CASE 2: Subquery with no HAVING clause
                     Project(
                         currentChild.output :+
                         Alias(
                             If(IsNull(alwaysTrueRef),
                                resultWithZeroTups.get,
                                aggValRef), origOutput.name)(exprId = origOutput.exprId),
                         Join(currentChild,
                              Project(query.output :+ alwaysTrueExpr, query),
                              LeftOuter, conditions.reduceOption(And), JoinHint.NONE))
     
                 } else {
                     // CASE 3: Subquery with HAVING clause. Pull the HAVING clause above the join.
                     // Need to modify any operators below the join to pass through all columns
                     // referenced in the HAVING clause.
                     var subqueryRoot: UnaryNode = aggNode
                     val havingInputs: Seq[NamedExpression] = aggNode.output
     
                     topPart.reverse.foreach {
                         case Project(projList, _) =>
                         subqueryRoot = Project(projList ++ havingInputs, subqueryRoot)
                         case s @ SubqueryAlias(alias, _) =>
                         subqueryRoot = SubqueryAlias(alias, subqueryRoot)
                         case op => sys.error(s"Unexpected operator $op in corelated subquery")
                     }
     
                     // CASE WHEN alwaysTrue IS NULL THEN resultOnZeroTups
                     //  WHEN NOT (original HAVING clause expr) THEN CAST(null AS <type of aggVal>)
                     //  ELSE (aggregate value) END AS (original column name)
                     val caseExpr = Alias(CaseWhen(Seq(
                         (IsNull(alwaysTrueRef), resultWithZeroTups.get),
                         (Not(havingNode.get.condition), 
                         Literal.create(null, aggValRef.dataType))),aggValRef),
                         origOutput.name)(exprId = origOutput.exprId)
     
                     Project(
                         currentChild.output :+ caseExpr,
                         Join(currentChild,
                              Project(subqueryRoot.output :+ alwaysTrueExpr, subqueryRoot),
                              LeftOuter, conditions.reduceOption(And), JoinHint.NONE))
     
                 }
             }
         }
     }
     ```

##### Left Semi/Anti Join的下推优化   

```scala
// 决定左右两侧哪一端才能下推
private def pushTo(leftChild: Join, rightChild: LogicalPlan, joinCond: Option[Expression])={
    val left = leftChild.left
    val right = leftChild.right
    val joinType = leftChild.joinType
    val rightOutput = rightChild.outputSet
    
    if (joinCond.nonEmpty) {
      // 拆分连接谓词
      val conditions = splitConjunctivePredicates(joinCond.get)
      val (leftConditions, rest) =
        conditions.partition(_.references.subsetOf(left.outputSet ++ rightOutput))
      val (rightConditions, commonConditions) =
        rest.partition(_.references.subsetOf(right.outputSet ++ rightOutput))
	 
      // 优先下推到左表中,其次下推到右表
      if (rest.isEmpty && leftConditions.nonEmpty) {
        // When the join conditions can be computed based on the left leg of
        // leftsemi/anti join then push the leftsemi/anti join to the left side.
        PushdownDirection.TO_LEFT_BRANCH
      } else if (leftConditions.isEmpty && rightConditions.nonEmpty && commonConditions.isEmpty) {
        // When the join conditions can be computed based on the attributes from right leg of
        // leftsemi/anti join then push the leftsemi/anti join to the right side.
        PushdownDirection.TO_RIGHT_BRANCH
      } else {
        PushdownDirection.NONE
      }
    } else {
      // 处理无join条件(外连接的状况)
      /**
       * When the join condition is empty,
       * 1) if this is a left outer join or inner join, push leftsemi/anti join down
       *    to the left leg of join.
       * 2) if a right outer join, to the right leg of join,
       */
      joinType match {
        case _: InnerLike | LeftOuter =>
          PushdownDirection.TO_LEFT_BRANCH
        case RightOuter =>
          PushdownDirection.TO_RIGHT_BRANCH
        case _ =>
          PushdownDirection.NONE
      }
    }
}
```

##### 使用谓词替换差集逻辑

**示例:**

```sql
SELECT a1, a2 FROM Tab1 WHERE a2 = 12 EXCEPT SELECT a1, a2 FROM Tab1 WHERE a1 = 5

-->

SELECT DISTINCT a1, a2 FROM Tab1 WHERE a2 = 12 AND (a1 is null OR a1 <> 5)
```

反转右节点的过滤条件时候,需要做到如下几点:

1. 合并所有过滤器
2. 将属性更新到左节点上
3. 添加合并逻辑

**实现细节**

```scala
/**
	plan 逻辑计划
	condition 条件表达式
*/
private def transformCondition(plan: LogicalPlan, condition: Expression): Option[Expression] {
    val attributeNameMap: Map[String, Attribute] = plan.output.map(x => (x.name, x)).toMap
    if (condition.references.forall(r => attributeNameMap.contains(r.name))) {
      val rewrittenCondition = condition.transform {
        case a: AttributeReference => attributeNameMap(a.name)
      }
      // We need to consider as False when the condition is NULL, otherwise we do not return those
      // rows containing NULL which are instead filtered in the Except right plan
      Some(Coalesce(Seq(rewrittenCondition, Literal.FalseLiteral)))
    } else {
      None
    }
}


// 合并过滤器
private def combineFilters(plan: LogicalPlan): LogicalPlan = {
    @tailrec
    def iterate(plan: LogicalPlan, acc: LogicalPlan): LogicalPlan = {
        if (acc.fastEquals(plan)) acc else iterate(acc, CombineFilters(acc))
    }
    iterate(plan, CombineFilters(plan))
}
```

##### 浮点数规范化

+ 确实是否需要规范化

  ```scala
  private def needNormalize(expr: Expression): Boolean = expr match {
      case KnownFloatingPointNormalized(_) => false
      case _ => needNormalize(expr.dataType)
  }
  
  private def needNormalize(dt: DataType): Boolean = dt match {
      case FloatType | DoubleType => true
      case StructType(fields) => fields.exists(f => needNormalize(f.dataType))
      case ArrayType(et, _) => needNormalize(et)
      // Currently MapType is not comparable and analyzer should fail earlier if this case happens.
      case _: MapType =>
      throw new IllegalStateException("grouping/join/window partition keys cannot be map type.")
      case _ => false
  }
  ```

+ 规范化实现细节

  ```scala
  private[sql] def normalize(expr: Expression): Expression = expr match {
      case _ if !needNormalize(expr) => expr
  
      case a: Alias =>
      	a.withNewChildren(Seq(normalize(a.child)))
  
      case CreateNamedStruct(children) =>
      	CreateNamedStruct(children.map(normalize))
  
      case CreateArray(children) =>
      	CreateArray(children.map(normalize))
  
      case CreateMap(children) =>
      	CreateMap(children.map(normalize))
  
      case _ if expr.dataType == FloatType || expr.dataType == DoubleType =>// 规范化空值或者零值
      	KnownFloatingPointNormalized(NormalizeNaNAndZero(expr))
  
      case _ if expr.dataType.isInstanceOf[StructType] =>
          val fields = expr.dataType.asInstanceOf[StructType].fields.indices.map { i =>
              normalize(GetStructField(expr, i))
          }
          CreateStruct(fields)
  
      case _ if expr.dataType.isInstanceOf[ArrayType] =>
          val ArrayType(et, containsNull) = expr.dataType
          val lv = NamedLambdaVariable("arg", et, containsNull)
          val function = normalize(lv)
          KnownFloatingPointNormalized(ArrayTransform(expr, LambdaFunction(function, Seq(lv))))
  
      case _ => throw new IllegalStateException(s"fail to normalize $expr")
  }
  ```

  + 优化空值/零值

  ```scala
  private lazy val normalizer: Any => Any = child.dataType match {
      case FloatType => (input: Any) => {
          val f = input.asInstanceOf[Float]
          if (f.isNaN) {
              Float.NaN
          } else if (f == -0.0f) {
              0.0f
          } else {
              f
          }
      }
  
      case DoubleType => (input: Any) => {
          val d = input.asInstanceOf[Double]
          if (d.isNaN) {
              Double.NaN
          } else if (d == -0.0d) {
              0.0d
          } else {
              d
          }
      }
  }
  ```

##### 内嵌列重命名

作为列修建的一个部分存在, 重命名的时候需要重写处理投影关系

```scala
def replaceToAliases(
    plan: LogicalPlan, // 逻辑计划
    nestedFieldToAlias: Map[ExtractValue, Alias], // 属性别名映射表
    attrToAliases: Map[ExprId, Seq[Alias]] // 表达式 -> 别名表
): LogicalPlan = plan match {
    case Project(projectList, child) =>
        Project(
            getNewProjectList(projectList, nestedFieldToAlias),
            replaceChildrenWithAliases(child, attrToAliases))
}
```

新的投影信息如下

```scala
def getNewProjectList(
    projectList: Seq[NamedExpression],
    nestedFieldToAlias: Map[ExtractValue, Alias]): Seq[NamedExpression] = {
    projectList.map(_.transform {
        case f: ExtractValue if nestedFieldToAlias.contains(f) =>
        nestedFieldToAlias(f).toAttribute
    }.asInstanceOf[NamedExpression])
}
```

使用新的别名替换逻辑计划

```scala
def replaceChildrenWithAliases(
    plan: LogicalPlan,
    attrToAliases: Map[ExprId, Seq[Alias]]): LogicalPlan = {
    plan.withNewChildren(plan.children.map { plan =>
        Project(plan.output.flatMap(a => attrToAliases.getOrElse(a.exprId, Seq(a))), plan)
    })
}
```

##### 基于CBO策略的Join重排序

