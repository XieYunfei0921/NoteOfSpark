#### catalog是什么

`Catalog`参考文件系统的树状结构设计, 最顶层是`catalog`,每一个数据目录包含多个`schema`. `relation`(表)以及视图`view`从属于`schema`.

用户使用密码登录到数据库, 每个用户都有默认的`catalog`和`schema`.其中目录,模式,表名唯一表示一个表,例如`database.schema.table`.`catalog`或者`schema`省略则会使用默认值. 但并非所有数据库都实现了`schema`这一层，比如`mysql`直接把`schema`和`database`等效了.

例如: 创建用户的时候会创建一个与用户账号同名的`schema`

#### schema 和 catalog的对比

引用schema和catalog主要用于解决数据库命名空间的冲突问题. 不同数据库schema和catalog设计不同, 最简单的, catalog是数据库名, schema是用户名



#### catalog的设计参考

catalog主要用于存储**元数据信息**, 包括数据库,数据表,视图,关系,函数等等. 例如, spark sql中对如下参数进行了记录.

```scala

//函数三要素,函数名称,函数参数列表,这里没有添加函数返回值类型
case class CatalogFunction(
    identifier: FunctionIdentifier,
    className: String,
    resources: Seq[FunctionResource])

// 描述存储格式
case class CatalogStorageFormat(
    locationUri: Option[URI],
    inputFormat: Option[String],
    outputFormat: Option[String],
    serde: Option[String],
    compressed: Boolean,
    properties: Map[String, String]) 

// 记录表分区信息
case class CatalogTablePartition(
    spec: CatalogTypes.TablePartitionSpec,
    storage: CatalogStorageFormat,
    parameters: Map[String, String] = Map.empty,
    createTime: Long = System.currentTimeMillis,
    lastAccessTime: Long = -1,
    stats: Option[CatalogStatistics] = None) 

// 表信息记录
case class CatalogTable(
    identifier: TableIdentifier,
    tableType: CatalogTableType,
    storage: CatalogStorageFormat,
    schema: StructType,
    provider: Option[String] = None,
    partitionColumnNames: Seq[String] = Seq.empty,
    bucketSpec: Option[BucketSpec] = None,
    owner: String = "",
    createTime: Long = System.currentTimeMillis,
    lastAccessTime: Long = -1,
    createVersion: String = "",
    properties: Map[String, String] = Map.empty,
    stats: Option[CatalogStatistics] = None,
    viewText: Option[String] = None,
    comment: Option[String] = None,
    unsupportedFeatures: Seq[String] = Seq.empty,
    tracksPartitionsInCatalog: Boolean = false,
    schemaPreservesCase: Boolean = true,
    ignoredProperties: Map[String, String] = Map.empty,
    viewOriginalText: Option[String] = None) 

// 记录数据库地址
case class CatalogDatabase(
    name: String,
    description: String,
    locationUri: URI,
    properties: Map[String, String])


// 记录hive表信息
case class HiveTableRelation(
    tableMeta: CatalogTable,
    dataCols: Seq[AttributeReference],
    partitionCols: Seq[AttributeReference],
    tableStats: Option[Statistics] = None)
```

其余的,比如设计视图和触发器,需要根据相应的特征,在命名空间内保证唯一确定这条元数据记录.



#### 如何监控外部对catalog数据的修改

在常用的DBMS中,会通过命令行执行`sql`,一些更新操作会引发数据目录中记录的变动. 如果使用观察者模式设计并获取这个变动. 之后可以结合其他中间件或者自己来实现一条消息总线和存储的功能.

例如, `spark sql`中`event`就是这么设计的

```scala
trait ExternalCatalogEventListener {
  def onEvent(event: ExternalCatalogEvent): Unit
}

trait DatabaseEvent extends ExternalCatalogEvent {
  val database: String
}

// 下面是各类实现,不详述,列出几个表示一下
case class CreateDatabasePreEvent(database: String) extends DatabaseEvent

case class CreateDatabaseEvent(database: String) extends DatabaseEvent

case class DropDatabasePreEvent(database: String) extends DatabaseEvent

case class DropDatabaseEvent(database: String) extends DatabaseEvent

case class AlterDatabasePreEvent(database: String) extends DatabaseEvent

case class AlterDatabaseEvent(database: String) extends DatabaseEvent

```

同理,可以设计表和函数的事件

```scala
trait FunctionEvent extends DatabaseEvent {
  val name: String
}

trait TableEvent extends DatabaseEvent {
  val name: String
}
```



#### 对临时表和全局临时表进行管理

通常情况下,一个查询中会遇到子查询,这个子查询在他的闭包范围内部有效,且在统一级别`AST`下唯一,所以说设计全局临时表则需要在`JVM`运行期间保持唯一,因此需要设计成大小写敏感.